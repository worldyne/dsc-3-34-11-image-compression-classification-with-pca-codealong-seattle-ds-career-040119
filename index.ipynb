{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Compression and Classification with PCA - code along\n",
    "\n",
    "## Introduction\n",
    "In the last lesson, we looked at how PCA plays an important role in the field of image processing by allowing us to compress and simplify high dimensional image data for faster processing and simplicity of analysis. In this code along, we shall look at applying these techniques to the popular MNIST dataset, before attempting to calculate Eigenfaces in the next lab. This code along style lab will introduce you to all the required steps which with an understanding of underlying mechanism.\n",
    "\n",
    "## Objectives\n",
    "You will be able to:\n",
    "- Apply PCA to MNIST, or a similar image based dataset\n",
    "- Inspect the effect of number of principal components on explained variance and vice versa, for image data.\n",
    "- Run a classifier using PCA components and inspect the impact on classification accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST DATASET\n",
    "\n",
    "The MNIST dataset contains handwritten digits. MNIST is a popular labeled dataset for practicing image processing techniques and contains a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from [NIST](https://www.nist.gov/srd/nist-special-database-19). The digits have been size-normalized and centered in a fixed-size image. Here is sample of images that you would find in MNIST dataset. \n",
    "\n",
    "<img src=\"mnist.png\" width=500>\n",
    "\n",
    "This is an excellent dataset for aspiring data scientists, wanting to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting.\n",
    "\n",
    "The MNIST database of handwritten digits is available on the following website: [MNIST Dataset](http://yann.lecun.com/exdb/mnist/). Do visit some of the provided links to see how researchers and practitioners are using this dataset for developing cutting machine learning algorithms in the domain of computer vision/image processing.\n",
    "\n",
    "\n",
    "Parameters | Number\n",
    "--- | ---\n",
    "Classes | 10\n",
    "Samples per class | ~7000 samples per class\n",
    "Samples total | 70000\n",
    "Dimensionality | 784\n",
    "Features | integers values from 0 to 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load this dataset into our working environment. First we need the necessary libraries required for this experiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Necessary Libraries\n",
    "\n",
    "```python\n",
    "#Â Import necessary libraries \n",
    "\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download and Inspect the Dataset\n",
    "\n",
    "MNIST dataset can be downloaded with scikit-learn for experimentation. We shall use `fetch_mldata()` to import this dataset into our environment. \n",
    "\n",
    "```python\n",
    "# Download the dataset\n",
    "digits = fetch_mldata('MNIST original')\n",
    "digits\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]),\n",
       " 'target': array(['5', '0', '4', ..., '4', '5', '6'], dtype=object),\n",
       " 'feature_names': ['pixel1',\n",
       "  'pixel2',\n",
       "  'pixel3',\n",
       "  'pixel4',\n",
       "  'pixel5',\n",
       "  'pixel6',\n",
       "  'pixel7',\n",
       "  'pixel8',\n",
       "  'pixel9',\n",
       "  'pixel10',\n",
       "  'pixel11',\n",
       "  'pixel12',\n",
       "  'pixel13',\n",
       "  'pixel14',\n",
       "  'pixel15',\n",
       "  'pixel16',\n",
       "  'pixel17',\n",
       "  'pixel18',\n",
       "  'pixel19',\n",
       "  'pixel20',\n",
       "  'pixel21',\n",
       "  'pixel22',\n",
       "  'pixel23',\n",
       "  'pixel24',\n",
       "  'pixel25',\n",
       "  'pixel26',\n",
       "  'pixel27',\n",
       "  'pixel28',\n",
       "  'pixel29',\n",
       "  'pixel30',\n",
       "  'pixel31',\n",
       "  'pixel32',\n",
       "  'pixel33',\n",
       "  'pixel34',\n",
       "  'pixel35',\n",
       "  'pixel36',\n",
       "  'pixel37',\n",
       "  'pixel38',\n",
       "  'pixel39',\n",
       "  'pixel40',\n",
       "  'pixel41',\n",
       "  'pixel42',\n",
       "  'pixel43',\n",
       "  'pixel44',\n",
       "  'pixel45',\n",
       "  'pixel46',\n",
       "  'pixel47',\n",
       "  'pixel48',\n",
       "  'pixel49',\n",
       "  'pixel50',\n",
       "  'pixel51',\n",
       "  'pixel52',\n",
       "  'pixel53',\n",
       "  'pixel54',\n",
       "  'pixel55',\n",
       "  'pixel56',\n",
       "  'pixel57',\n",
       "  'pixel58',\n",
       "  'pixel59',\n",
       "  'pixel60',\n",
       "  'pixel61',\n",
       "  'pixel62',\n",
       "  'pixel63',\n",
       "  'pixel64',\n",
       "  'pixel65',\n",
       "  'pixel66',\n",
       "  'pixel67',\n",
       "  'pixel68',\n",
       "  'pixel69',\n",
       "  'pixel70',\n",
       "  'pixel71',\n",
       "  'pixel72',\n",
       "  'pixel73',\n",
       "  'pixel74',\n",
       "  'pixel75',\n",
       "  'pixel76',\n",
       "  'pixel77',\n",
       "  'pixel78',\n",
       "  'pixel79',\n",
       "  'pixel80',\n",
       "  'pixel81',\n",
       "  'pixel82',\n",
       "  'pixel83',\n",
       "  'pixel84',\n",
       "  'pixel85',\n",
       "  'pixel86',\n",
       "  'pixel87',\n",
       "  'pixel88',\n",
       "  'pixel89',\n",
       "  'pixel90',\n",
       "  'pixel91',\n",
       "  'pixel92',\n",
       "  'pixel93',\n",
       "  'pixel94',\n",
       "  'pixel95',\n",
       "  'pixel96',\n",
       "  'pixel97',\n",
       "  'pixel98',\n",
       "  'pixel99',\n",
       "  'pixel100',\n",
       "  'pixel101',\n",
       "  'pixel102',\n",
       "  'pixel103',\n",
       "  'pixel104',\n",
       "  'pixel105',\n",
       "  'pixel106',\n",
       "  'pixel107',\n",
       "  'pixel108',\n",
       "  'pixel109',\n",
       "  'pixel110',\n",
       "  'pixel111',\n",
       "  'pixel112',\n",
       "  'pixel113',\n",
       "  'pixel114',\n",
       "  'pixel115',\n",
       "  'pixel116',\n",
       "  'pixel117',\n",
       "  'pixel118',\n",
       "  'pixel119',\n",
       "  'pixel120',\n",
       "  'pixel121',\n",
       "  'pixel122',\n",
       "  'pixel123',\n",
       "  'pixel124',\n",
       "  'pixel125',\n",
       "  'pixel126',\n",
       "  'pixel127',\n",
       "  'pixel128',\n",
       "  'pixel129',\n",
       "  'pixel130',\n",
       "  'pixel131',\n",
       "  'pixel132',\n",
       "  'pixel133',\n",
       "  'pixel134',\n",
       "  'pixel135',\n",
       "  'pixel136',\n",
       "  'pixel137',\n",
       "  'pixel138',\n",
       "  'pixel139',\n",
       "  'pixel140',\n",
       "  'pixel141',\n",
       "  'pixel142',\n",
       "  'pixel143',\n",
       "  'pixel144',\n",
       "  'pixel145',\n",
       "  'pixel146',\n",
       "  'pixel147',\n",
       "  'pixel148',\n",
       "  'pixel149',\n",
       "  'pixel150',\n",
       "  'pixel151',\n",
       "  'pixel152',\n",
       "  'pixel153',\n",
       "  'pixel154',\n",
       "  'pixel155',\n",
       "  'pixel156',\n",
       "  'pixel157',\n",
       "  'pixel158',\n",
       "  'pixel159',\n",
       "  'pixel160',\n",
       "  'pixel161',\n",
       "  'pixel162',\n",
       "  'pixel163',\n",
       "  'pixel164',\n",
       "  'pixel165',\n",
       "  'pixel166',\n",
       "  'pixel167',\n",
       "  'pixel168',\n",
       "  'pixel169',\n",
       "  'pixel170',\n",
       "  'pixel171',\n",
       "  'pixel172',\n",
       "  'pixel173',\n",
       "  'pixel174',\n",
       "  'pixel175',\n",
       "  'pixel176',\n",
       "  'pixel177',\n",
       "  'pixel178',\n",
       "  'pixel179',\n",
       "  'pixel180',\n",
       "  'pixel181',\n",
       "  'pixel182',\n",
       "  'pixel183',\n",
       "  'pixel184',\n",
       "  'pixel185',\n",
       "  'pixel186',\n",
       "  'pixel187',\n",
       "  'pixel188',\n",
       "  'pixel189',\n",
       "  'pixel190',\n",
       "  'pixel191',\n",
       "  'pixel192',\n",
       "  'pixel193',\n",
       "  'pixel194',\n",
       "  'pixel195',\n",
       "  'pixel196',\n",
       "  'pixel197',\n",
       "  'pixel198',\n",
       "  'pixel199',\n",
       "  'pixel200',\n",
       "  'pixel201',\n",
       "  'pixel202',\n",
       "  'pixel203',\n",
       "  'pixel204',\n",
       "  'pixel205',\n",
       "  'pixel206',\n",
       "  'pixel207',\n",
       "  'pixel208',\n",
       "  'pixel209',\n",
       "  'pixel210',\n",
       "  'pixel211',\n",
       "  'pixel212',\n",
       "  'pixel213',\n",
       "  'pixel214',\n",
       "  'pixel215',\n",
       "  'pixel216',\n",
       "  'pixel217',\n",
       "  'pixel218',\n",
       "  'pixel219',\n",
       "  'pixel220',\n",
       "  'pixel221',\n",
       "  'pixel222',\n",
       "  'pixel223',\n",
       "  'pixel224',\n",
       "  'pixel225',\n",
       "  'pixel226',\n",
       "  'pixel227',\n",
       "  'pixel228',\n",
       "  'pixel229',\n",
       "  'pixel230',\n",
       "  'pixel231',\n",
       "  'pixel232',\n",
       "  'pixel233',\n",
       "  'pixel234',\n",
       "  'pixel235',\n",
       "  'pixel236',\n",
       "  'pixel237',\n",
       "  'pixel238',\n",
       "  'pixel239',\n",
       "  'pixel240',\n",
       "  'pixel241',\n",
       "  'pixel242',\n",
       "  'pixel243',\n",
       "  'pixel244',\n",
       "  'pixel245',\n",
       "  'pixel246',\n",
       "  'pixel247',\n",
       "  'pixel248',\n",
       "  'pixel249',\n",
       "  'pixel250',\n",
       "  'pixel251',\n",
       "  'pixel252',\n",
       "  'pixel253',\n",
       "  'pixel254',\n",
       "  'pixel255',\n",
       "  'pixel256',\n",
       "  'pixel257',\n",
       "  'pixel258',\n",
       "  'pixel259',\n",
       "  'pixel260',\n",
       "  'pixel261',\n",
       "  'pixel262',\n",
       "  'pixel263',\n",
       "  'pixel264',\n",
       "  'pixel265',\n",
       "  'pixel266',\n",
       "  'pixel267',\n",
       "  'pixel268',\n",
       "  'pixel269',\n",
       "  'pixel270',\n",
       "  'pixel271',\n",
       "  'pixel272',\n",
       "  'pixel273',\n",
       "  'pixel274',\n",
       "  'pixel275',\n",
       "  'pixel276',\n",
       "  'pixel277',\n",
       "  'pixel278',\n",
       "  'pixel279',\n",
       "  'pixel280',\n",
       "  'pixel281',\n",
       "  'pixel282',\n",
       "  'pixel283',\n",
       "  'pixel284',\n",
       "  'pixel285',\n",
       "  'pixel286',\n",
       "  'pixel287',\n",
       "  'pixel288',\n",
       "  'pixel289',\n",
       "  'pixel290',\n",
       "  'pixel291',\n",
       "  'pixel292',\n",
       "  'pixel293',\n",
       "  'pixel294',\n",
       "  'pixel295',\n",
       "  'pixel296',\n",
       "  'pixel297',\n",
       "  'pixel298',\n",
       "  'pixel299',\n",
       "  'pixel300',\n",
       "  'pixel301',\n",
       "  'pixel302',\n",
       "  'pixel303',\n",
       "  'pixel304',\n",
       "  'pixel305',\n",
       "  'pixel306',\n",
       "  'pixel307',\n",
       "  'pixel308',\n",
       "  'pixel309',\n",
       "  'pixel310',\n",
       "  'pixel311',\n",
       "  'pixel312',\n",
       "  'pixel313',\n",
       "  'pixel314',\n",
       "  'pixel315',\n",
       "  'pixel316',\n",
       "  'pixel317',\n",
       "  'pixel318',\n",
       "  'pixel319',\n",
       "  'pixel320',\n",
       "  'pixel321',\n",
       "  'pixel322',\n",
       "  'pixel323',\n",
       "  'pixel324',\n",
       "  'pixel325',\n",
       "  'pixel326',\n",
       "  'pixel327',\n",
       "  'pixel328',\n",
       "  'pixel329',\n",
       "  'pixel330',\n",
       "  'pixel331',\n",
       "  'pixel332',\n",
       "  'pixel333',\n",
       "  'pixel334',\n",
       "  'pixel335',\n",
       "  'pixel336',\n",
       "  'pixel337',\n",
       "  'pixel338',\n",
       "  'pixel339',\n",
       "  'pixel340',\n",
       "  'pixel341',\n",
       "  'pixel342',\n",
       "  'pixel343',\n",
       "  'pixel344',\n",
       "  'pixel345',\n",
       "  'pixel346',\n",
       "  'pixel347',\n",
       "  'pixel348',\n",
       "  'pixel349',\n",
       "  'pixel350',\n",
       "  'pixel351',\n",
       "  'pixel352',\n",
       "  'pixel353',\n",
       "  'pixel354',\n",
       "  'pixel355',\n",
       "  'pixel356',\n",
       "  'pixel357',\n",
       "  'pixel358',\n",
       "  'pixel359',\n",
       "  'pixel360',\n",
       "  'pixel361',\n",
       "  'pixel362',\n",
       "  'pixel363',\n",
       "  'pixel364',\n",
       "  'pixel365',\n",
       "  'pixel366',\n",
       "  'pixel367',\n",
       "  'pixel368',\n",
       "  'pixel369',\n",
       "  'pixel370',\n",
       "  'pixel371',\n",
       "  'pixel372',\n",
       "  'pixel373',\n",
       "  'pixel374',\n",
       "  'pixel375',\n",
       "  'pixel376',\n",
       "  'pixel377',\n",
       "  'pixel378',\n",
       "  'pixel379',\n",
       "  'pixel380',\n",
       "  'pixel381',\n",
       "  'pixel382',\n",
       "  'pixel383',\n",
       "  'pixel384',\n",
       "  'pixel385',\n",
       "  'pixel386',\n",
       "  'pixel387',\n",
       "  'pixel388',\n",
       "  'pixel389',\n",
       "  'pixel390',\n",
       "  'pixel391',\n",
       "  'pixel392',\n",
       "  'pixel393',\n",
       "  'pixel394',\n",
       "  'pixel395',\n",
       "  'pixel396',\n",
       "  'pixel397',\n",
       "  'pixel398',\n",
       "  'pixel399',\n",
       "  'pixel400',\n",
       "  'pixel401',\n",
       "  'pixel402',\n",
       "  'pixel403',\n",
       "  'pixel404',\n",
       "  'pixel405',\n",
       "  'pixel406',\n",
       "  'pixel407',\n",
       "  'pixel408',\n",
       "  'pixel409',\n",
       "  'pixel410',\n",
       "  'pixel411',\n",
       "  'pixel412',\n",
       "  'pixel413',\n",
       "  'pixel414',\n",
       "  'pixel415',\n",
       "  'pixel416',\n",
       "  'pixel417',\n",
       "  'pixel418',\n",
       "  'pixel419',\n",
       "  'pixel420',\n",
       "  'pixel421',\n",
       "  'pixel422',\n",
       "  'pixel423',\n",
       "  'pixel424',\n",
       "  'pixel425',\n",
       "  'pixel426',\n",
       "  'pixel427',\n",
       "  'pixel428',\n",
       "  'pixel429',\n",
       "  'pixel430',\n",
       "  'pixel431',\n",
       "  'pixel432',\n",
       "  'pixel433',\n",
       "  'pixel434',\n",
       "  'pixel435',\n",
       "  'pixel436',\n",
       "  'pixel437',\n",
       "  'pixel438',\n",
       "  'pixel439',\n",
       "  'pixel440',\n",
       "  'pixel441',\n",
       "  'pixel442',\n",
       "  'pixel443',\n",
       "  'pixel444',\n",
       "  'pixel445',\n",
       "  'pixel446',\n",
       "  'pixel447',\n",
       "  'pixel448',\n",
       "  'pixel449',\n",
       "  'pixel450',\n",
       "  'pixel451',\n",
       "  'pixel452',\n",
       "  'pixel453',\n",
       "  'pixel454',\n",
       "  'pixel455',\n",
       "  'pixel456',\n",
       "  'pixel457',\n",
       "  'pixel458',\n",
       "  'pixel459',\n",
       "  'pixel460',\n",
       "  'pixel461',\n",
       "  'pixel462',\n",
       "  'pixel463',\n",
       "  'pixel464',\n",
       "  'pixel465',\n",
       "  'pixel466',\n",
       "  'pixel467',\n",
       "  'pixel468',\n",
       "  'pixel469',\n",
       "  'pixel470',\n",
       "  'pixel471',\n",
       "  'pixel472',\n",
       "  'pixel473',\n",
       "  'pixel474',\n",
       "  'pixel475',\n",
       "  'pixel476',\n",
       "  'pixel477',\n",
       "  'pixel478',\n",
       "  'pixel479',\n",
       "  'pixel480',\n",
       "  'pixel481',\n",
       "  'pixel482',\n",
       "  'pixel483',\n",
       "  'pixel484',\n",
       "  'pixel485',\n",
       "  'pixel486',\n",
       "  'pixel487',\n",
       "  'pixel488',\n",
       "  'pixel489',\n",
       "  'pixel490',\n",
       "  'pixel491',\n",
       "  'pixel492',\n",
       "  'pixel493',\n",
       "  'pixel494',\n",
       "  'pixel495',\n",
       "  'pixel496',\n",
       "  'pixel497',\n",
       "  'pixel498',\n",
       "  'pixel499',\n",
       "  'pixel500',\n",
       "  'pixel501',\n",
       "  'pixel502',\n",
       "  'pixel503',\n",
       "  'pixel504',\n",
       "  'pixel505',\n",
       "  'pixel506',\n",
       "  'pixel507',\n",
       "  'pixel508',\n",
       "  'pixel509',\n",
       "  'pixel510',\n",
       "  'pixel511',\n",
       "  'pixel512',\n",
       "  'pixel513',\n",
       "  'pixel514',\n",
       "  'pixel515',\n",
       "  'pixel516',\n",
       "  'pixel517',\n",
       "  'pixel518',\n",
       "  'pixel519',\n",
       "  'pixel520',\n",
       "  'pixel521',\n",
       "  'pixel522',\n",
       "  'pixel523',\n",
       "  'pixel524',\n",
       "  'pixel525',\n",
       "  'pixel526',\n",
       "  'pixel527',\n",
       "  'pixel528',\n",
       "  'pixel529',\n",
       "  'pixel530',\n",
       "  'pixel531',\n",
       "  'pixel532',\n",
       "  'pixel533',\n",
       "  'pixel534',\n",
       "  'pixel535',\n",
       "  'pixel536',\n",
       "  'pixel537',\n",
       "  'pixel538',\n",
       "  'pixel539',\n",
       "  'pixel540',\n",
       "  'pixel541',\n",
       "  'pixel542',\n",
       "  'pixel543',\n",
       "  'pixel544',\n",
       "  'pixel545',\n",
       "  'pixel546',\n",
       "  'pixel547',\n",
       "  'pixel548',\n",
       "  'pixel549',\n",
       "  'pixel550',\n",
       "  'pixel551',\n",
       "  'pixel552',\n",
       "  'pixel553',\n",
       "  'pixel554',\n",
       "  'pixel555',\n",
       "  'pixel556',\n",
       "  'pixel557',\n",
       "  'pixel558',\n",
       "  'pixel559',\n",
       "  'pixel560',\n",
       "  'pixel561',\n",
       "  'pixel562',\n",
       "  'pixel563',\n",
       "  'pixel564',\n",
       "  'pixel565',\n",
       "  'pixel566',\n",
       "  'pixel567',\n",
       "  'pixel568',\n",
       "  'pixel569',\n",
       "  'pixel570',\n",
       "  'pixel571',\n",
       "  'pixel572',\n",
       "  'pixel573',\n",
       "  'pixel574',\n",
       "  'pixel575',\n",
       "  'pixel576',\n",
       "  'pixel577',\n",
       "  'pixel578',\n",
       "  'pixel579',\n",
       "  'pixel580',\n",
       "  'pixel581',\n",
       "  'pixel582',\n",
       "  'pixel583',\n",
       "  'pixel584',\n",
       "  'pixel585',\n",
       "  'pixel586',\n",
       "  'pixel587',\n",
       "  'pixel588',\n",
       "  'pixel589',\n",
       "  'pixel590',\n",
       "  'pixel591',\n",
       "  'pixel592',\n",
       "  'pixel593',\n",
       "  'pixel594',\n",
       "  'pixel595',\n",
       "  'pixel596',\n",
       "  'pixel597',\n",
       "  'pixel598',\n",
       "  'pixel599',\n",
       "  'pixel600',\n",
       "  'pixel601',\n",
       "  'pixel602',\n",
       "  'pixel603',\n",
       "  'pixel604',\n",
       "  'pixel605',\n",
       "  'pixel606',\n",
       "  'pixel607',\n",
       "  'pixel608',\n",
       "  'pixel609',\n",
       "  'pixel610',\n",
       "  'pixel611',\n",
       "  'pixel612',\n",
       "  'pixel613',\n",
       "  'pixel614',\n",
       "  'pixel615',\n",
       "  'pixel616',\n",
       "  'pixel617',\n",
       "  'pixel618',\n",
       "  'pixel619',\n",
       "  'pixel620',\n",
       "  'pixel621',\n",
       "  'pixel622',\n",
       "  'pixel623',\n",
       "  'pixel624',\n",
       "  'pixel625',\n",
       "  'pixel626',\n",
       "  'pixel627',\n",
       "  'pixel628',\n",
       "  'pixel629',\n",
       "  'pixel630',\n",
       "  'pixel631',\n",
       "  'pixel632',\n",
       "  'pixel633',\n",
       "  'pixel634',\n",
       "  'pixel635',\n",
       "  'pixel636',\n",
       "  'pixel637',\n",
       "  'pixel638',\n",
       "  'pixel639',\n",
       "  'pixel640',\n",
       "  'pixel641',\n",
       "  'pixel642',\n",
       "  'pixel643',\n",
       "  'pixel644',\n",
       "  'pixel645',\n",
       "  'pixel646',\n",
       "  'pixel647',\n",
       "  'pixel648',\n",
       "  'pixel649',\n",
       "  'pixel650',\n",
       "  'pixel651',\n",
       "  'pixel652',\n",
       "  'pixel653',\n",
       "  'pixel654',\n",
       "  'pixel655',\n",
       "  'pixel656',\n",
       "  'pixel657',\n",
       "  'pixel658',\n",
       "  'pixel659',\n",
       "  'pixel660',\n",
       "  'pixel661',\n",
       "  'pixel662',\n",
       "  'pixel663',\n",
       "  'pixel664',\n",
       "  'pixel665',\n",
       "  'pixel666',\n",
       "  'pixel667',\n",
       "  'pixel668',\n",
       "  'pixel669',\n",
       "  'pixel670',\n",
       "  'pixel671',\n",
       "  'pixel672',\n",
       "  'pixel673',\n",
       "  'pixel674',\n",
       "  'pixel675',\n",
       "  'pixel676',\n",
       "  'pixel677',\n",
       "  'pixel678',\n",
       "  'pixel679',\n",
       "  'pixel680',\n",
       "  'pixel681',\n",
       "  'pixel682',\n",
       "  'pixel683',\n",
       "  'pixel684',\n",
       "  'pixel685',\n",
       "  'pixel686',\n",
       "  'pixel687',\n",
       "  'pixel688',\n",
       "  'pixel689',\n",
       "  'pixel690',\n",
       "  'pixel691',\n",
       "  'pixel692',\n",
       "  'pixel693',\n",
       "  'pixel694',\n",
       "  'pixel695',\n",
       "  'pixel696',\n",
       "  'pixel697',\n",
       "  'pixel698',\n",
       "  'pixel699',\n",
       "  'pixel700',\n",
       "  'pixel701',\n",
       "  'pixel702',\n",
       "  'pixel703',\n",
       "  'pixel704',\n",
       "  'pixel705',\n",
       "  'pixel706',\n",
       "  'pixel707',\n",
       "  'pixel708',\n",
       "  'pixel709',\n",
       "  'pixel710',\n",
       "  'pixel711',\n",
       "  'pixel712',\n",
       "  'pixel713',\n",
       "  'pixel714',\n",
       "  'pixel715',\n",
       "  'pixel716',\n",
       "  'pixel717',\n",
       "  'pixel718',\n",
       "  'pixel719',\n",
       "  'pixel720',\n",
       "  'pixel721',\n",
       "  'pixel722',\n",
       "  'pixel723',\n",
       "  'pixel724',\n",
       "  'pixel725',\n",
       "  'pixel726',\n",
       "  'pixel727',\n",
       "  'pixel728',\n",
       "  'pixel729',\n",
       "  'pixel730',\n",
       "  'pixel731',\n",
       "  'pixel732',\n",
       "  'pixel733',\n",
       "  'pixel734',\n",
       "  'pixel735',\n",
       "  'pixel736',\n",
       "  'pixel737',\n",
       "  'pixel738',\n",
       "  'pixel739',\n",
       "  'pixel740',\n",
       "  'pixel741',\n",
       "  'pixel742',\n",
       "  'pixel743',\n",
       "  'pixel744',\n",
       "  'pixel745',\n",
       "  'pixel746',\n",
       "  'pixel747',\n",
       "  'pixel748',\n",
       "  'pixel749',\n",
       "  'pixel750',\n",
       "  'pixel751',\n",
       "  'pixel752',\n",
       "  'pixel753',\n",
       "  'pixel754',\n",
       "  'pixel755',\n",
       "  'pixel756',\n",
       "  'pixel757',\n",
       "  'pixel758',\n",
       "  'pixel759',\n",
       "  'pixel760',\n",
       "  'pixel761',\n",
       "  'pixel762',\n",
       "  'pixel763',\n",
       "  'pixel764',\n",
       "  'pixel765',\n",
       "  'pixel766',\n",
       "  'pixel767',\n",
       "  'pixel768',\n",
       "  'pixel769',\n",
       "  'pixel770',\n",
       "  'pixel771',\n",
       "  'pixel772',\n",
       "  'pixel773',\n",
       "  'pixel774',\n",
       "  'pixel775',\n",
       "  'pixel776',\n",
       "  'pixel777',\n",
       "  'pixel778',\n",
       "  'pixel779',\n",
       "  'pixel780',\n",
       "  'pixel781',\n",
       "  'pixel782',\n",
       "  'pixel783',\n",
       "  'pixel784'],\n",
       " 'DESCR': \"**Author**: Yann LeCun, Corinna Cortes, Christopher J.C. Burges  \\n**Source**: [MNIST Website](http://yann.lecun.com/exdb/mnist/) - Date unknown  \\n**Please cite**:  \\n\\nThe MNIST database of handwritten digits with 784 features, raw data available at: http://yann.lecun.com/exdb/mnist/. It can be split in a training set of the first 60,000 examples, and a test set of 10,000 examples  \\n\\nIt is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. It is a good database for people who want to try learning techniques and pattern recognition methods on real-world data while spending minimal efforts on preprocessing and formatting. The original black and white (bilevel) images from NIST were size normalized to fit in a 20x20 pixel box while preserving their aspect ratio. The resulting images contain grey levels as a result of the anti-aliasing technique used by the normalization algorithm. the images were centered in a 28x28 image by computing the center of mass of the pixels, and translating the image so as to position this point at the center of the 28x28 field.  \\n\\nWith some classification methods (particularly template-based methods, such as SVM and K-nearest neighbors), the error rate improves when the digits are centered by bounding box rather than center of mass. If you do this kind of pre-processing, you should report it in your publications. The MNIST database was constructed from NIST's NIST originally designated SD-3 as their training set and SD-1 as their test set. However, SD-3 is much cleaner and easier to recognize than SD-1. The reason for this can be found on the fact that SD-3 was collected among Census Bureau employees, while SD-1 was collected among high-school students. Drawing sensible conclusions from learning experiments requires that the result be independent of the choice of training set and test among the complete set of samples. Therefore it was necessary to build a new database by mixing NIST's datasets.  \\n\\nThe MNIST training set is composed of 30,000 patterns from SD-3 and 30,000 patterns from SD-1. Our test set was composed of 5,000 patterns from SD-3 and 5,000 patterns from SD-1. The 60,000 pattern training set contained examples from approximately 250 writers. We made sure that the sets of writers of the training set and test set were disjoint. SD-1 contains 58,527 digit images written by 500 different writers. In contrast to SD-3, where blocks of data from each writer appeared in sequence, the data in SD-1 is scrambled. Writer identities for SD-1 is available and we used this information to unscramble the writers. We then split SD-1 in two: characters written by the first 250 writers went into our new training set. The remaining 250 writers were placed in our test set. Thus we had two sets with nearly 30,000 examples each. The new training set was completed with enough examples from SD-3, starting at pattern # 0, to make a full set of 60,000 training patterns. Similarly, the new test set was completed with SD-3 examples starting at pattern # 35,000 to make a full set with 60,000 test patterns. Only a subset of 10,000 test images (5,000 from SD-1 and 5,000 from SD-3) is available on this site. The full 60,000 sample training set is available.\\n\\nDownloaded from openml.org.\",\n",
       " 'details': {'id': '554',\n",
       "  'name': 'mnist_784',\n",
       "  'version': '1',\n",
       "  'format': 'ARFF',\n",
       "  'upload_date': '2014-09-29T03:28:38',\n",
       "  'licence': 'Public',\n",
       "  'url': 'https://www.openml.org/data/v1/download/52667/mnist_784.arff',\n",
       "  'file_id': '52667',\n",
       "  'default_target_attribute': 'class',\n",
       "  'tag': ['AzurePilot',\n",
       "   'OpenML-CC18',\n",
       "   'OpenML100',\n",
       "   'study_1',\n",
       "   'study_123',\n",
       "   'study_41',\n",
       "   'study_99',\n",
       "   'vision'],\n",
       "  'visibility': 'public',\n",
       "  'status': 'active',\n",
       "  'processing_date': '2018-10-03 21:23:30',\n",
       "  'md5_checksum': '0298d579eb1b86163de7723944c7e495'},\n",
       " 'categories': {},\n",
       " 'url': 'https://www.openml.org/d/554'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# code here \n",
    "digits = fetch_openml('mnist_784', version=1, cache=True)\n",
    "digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains both features (as digits.data) and target labels (as digits.target). Let's quickly check these for size. \n",
    "\n",
    "```python\n",
    "#Â Features in MNIST\n",
    "feat = digits.data\n",
    "print('Features:', feat.shape)\n",
    "\n",
    "# Targets in MNIST\n",
    "target = digits.target\n",
    "print('Target:', target.shape)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features (70000, 784)\n",
      "Target: (70000,)\n"
     ]
    }
   ],
   "source": [
    "# code here \n",
    "feat = digits.data\n",
    "print('Features', feat.shape)\n",
    "target = digits.target\n",
    "print('Target:', target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Viewing Images and labels in the dataset \n",
    "Above we can see that data is saved as arrays of 0/1 digits, following the digitization approach we saw in the previous lesson. We can visualize these arrays as images as shown below:\n",
    "\n",
    "```python\n",
    "#Â View the first image\n",
    "first_image = digits.data[0]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print ('Label:',digits.target[0])\n",
    "\n",
    "# View last image \n",
    "last_image = digits.data[-1]\n",
    "first_image = np.array(last_image, dtype='float')\n",
    "pixels = last_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print ('Label:',digits.target[-1])\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAABpxJREFUeJzt3TtIlv0fx/G/2VnqsTaL5sClA4VD0BFqstZoiJoMKhclAofGoLayLZqiFsnBpUioIYJwKDpADkJEQy1iQQ1F+Kz/ofvrk90e8vN6jX64ui6qNxf069aW6enp/wFL37KFfgBgfogdQogdQogdQogdQiyf5/v5p3+Yey2/+qI3O4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4QQO4RYvtAPwNz6+fNnuX/+/HlO7z84ONhw+/btW3nt+Ph4ud+4caPc+/v7G253794tr129enW5X7x4sdwvXbpU7gvBmx1CiB1CiB1CiB1CiB1CiB1CiB1COGefB+/fvy/379+/l/vTp0/L/cmTJw23qamp8tqhoaFyX0hbtmwp9/Pnz5f78PBww23dunXltdu2bSv3ffv2lfti5M0OIcQOIcQOIcQOIcQOIcQOIVqmp6fn837zerP58vz583I/ePBguc/1x0wXq9bW1nK/detWube1tc363ps2bSr3DRs2lPvWrVtnfe950PKrL3qzQwixQwixQwixQwixQwixQwixQwjn7E0wOTlZ7l1dXeU+MTHRzMdpqpmefabz6EePHjXcVq5cWV6b+v8PmsA5OyQTO4QQO4QQO4QQO4QQO4QQO4TwraSbYOPGjeV+9erVch8ZGSn3HTt2lHtvb2+5V7Zv317uo6Oj5T7TZ8pfv37dcLt27Vp5Lc3lzQ4hxA4hxA4hxA4hxA4hxA4hxA4hfJ59Efjy5Uu5z/TjhXt6ehpuN2/eLK+9fft2uZ84caLcWZR8nh2SiR1CiB1CiB1CiB1CiB1CiB1C+Dz7IrB+/fo/uv6ff/6Z9bUzncMfP3683Jct8774W/iTghBihxBihxBihxBihxBihxA+4roEfP36teHW3d1dXvv48eNyv3//frkfPny43FkQPuIKycQOIcQOIcQOIcQOIcQOIcQOIZyzL3ETExPlvnPnznJvb28v9wMHDpT7rl27Gm5nz54tr21p+eVxMTNzzg7JxA4hxA4hxA4hxA4hxA4hxA4hnLOHGx4eLvfTp0+X+0w/brpy+fLlcj958mS5d3R0zPreS5xzdkgmdgghdgghdgghdgghdgghdgjhnJ3Sq1evyr2vr6/cR0dHZ33vM2fOlPvAwEC5b968edb3/ss5Z4dkYocQYocQYocQYocQYocQYocQztn5I1NTU+U+MjLScDt16lR57Ux/Nw8dOlTuDx8+LPclzDk7JBM7hBA7hBA7hBA7hBA7hHD0xoJZtWpVuf/48aPcV6xYUe4PHjxouO3fv7+89i/n6A2SiR1CiB1CiB1CiB1CiB1CiB1CLF/oB2Bxe/nyZbkPDQ2V+9jYWMNtpnP0mXR2dpb73r17/+jXX2q82SGE2CGE2CGE2CGE2CGE2CGE2CGEc/Ylbnx8vNyvX79e7vfu3Sv3jx8//vYz/VfLl9d/PTs6Osp92TLvsv/ndwNCiB1CiB1CiB1CiB1CiB1CiB1COGf/C8x0ln3nzp2G2+DgYHntu3fvZvNITbF79+5yHxgYKPejR48283GWPG92CCF2CCF2CCF2CCF2CCF2COHobR58+vSp3N+8eVPu586dK/e3b9/+9jM1S1dXV7lfuHCh4Xbs2LHyWh9RbS6/mxBC7BBC7BBC7BBC7BBC7BBC7BDCOft/NDk52XDr6ekpr33x4kW5T0xMzOqZmmHPnj3l3tfXV+5Hjhwp9zVr1vz2MzE3vNkhhNghhNghhNghhNghhNghhNghRMw5+7Nnz8r9ypUr5T42NtZw+/Dhw6yeqVnWrl3bcOvt7S2vnenbNbe1tc3qmVh8vNkhhNghhNghhNghhNghhNghhNghRMw5+/Dw8B/tf6Kzs7Pcu7u7y721tbXc+/v7G27t7e3lteTwZocQYocQYocQYocQYocQYocQYocQLdPT0/N5v3m9GYRq+dUXvdkhhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghhNghxHz/yOZffotbYO55s0MIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUMIsUOIfwGsbAOpXUu9/QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n"
     ]
    }
   ],
   "source": [
    "# code here \n",
    "first_image = digits.data[0]\n",
    "first_image = np.array(first_image, dtype='float')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "plt.imshow(pixels, cmap='gray_r')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "print('Label:', digits.target[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we visualized the first and last image in the features dataset and pulled their labels for the target. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Standardization\n",
    "\n",
    "Just like any other other dataset, the first step in applying PCA is always normalization of data. We shall use the` StandardScaler()` from scikit-learn to standardize the features set. Remember, targets are just class labels and don't need any pre-processing. \n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Create a scalar instance \n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the features only, labels dont need transformation\n",
    "digits.data = scaler.fit_transform(digits.data)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "\n",
    "digits.data = ss.fit_transform(digits.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA with 95% Variance Retention\n",
    "\n",
    "Earlier, we looked an instantiating PCA with a set number of components. We can also run a PCA while defining the required amount of variance that we expect our resulting principal components to retain. This can be passed in as a value from 0 (no variance) - 1 (100% variance). Let's try it with 95% variance retention with our data and see how many components we need.  \n",
    "\n",
    "```python\n",
    "#Â Perform PCA \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.95) #Â Retain 95% of the variance\n",
    "digits_low_dim = pca.fit_transform(digits.data)\n",
    "pca.n_components_ # Check number of components for required variance\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# code here \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.95)\n",
    "digits_low_dim = pca.fit_transform(digits.data)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need 332 components in total to explain 95% of variation in the data. Not a bad start. \n",
    "\n",
    "> __Going from 784 features to 332 components help reduce the running time of a supervised learning algorithm. We can also go from compressed representation back to an approximation of the original high dimensional data (784 components).__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA - Inverse Transform (transforming low dimensional, data back to its original space)\n",
    "\n",
    "\n",
    "We can compare an observations from before and after PCA to see if there is any loss in the quality of the image. `pca.inverse_transform()` method allows us to reconstruct the image achieve this goal. Visit [this link](https://stats.stackexchange.com/questions/229092/how-to-reverse-pca-and-reconstruct-original-variables-from-several-principal-com) for details on how this method works behind the scenes. \n",
    "\n",
    "> Linear dimensionality reduction using Singular Value Decomposition of the data to project it to a lower dimensional space\n",
    "\n",
    "```python\n",
    "#Â Reconstruct the original image \n",
    "reconstruction = pca.inverse_transform(digits_low_dim)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "reconstruction = pca.inverse_transform(digits_low_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we can now view pre and post PCA data for a particular example in our dataset as shown below:\n",
    "    \n",
    "```python\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.figure(figsize=(8,4));\n",
    "\n",
    "# Original Image\n",
    "plt.subplot(1, 2, 1);\n",
    "plt.imshow(feat[1].reshape(28,28))\n",
    "plt.xlabel('784 components', fontsize = 14)\n",
    "plt.title('Original Image', fontsize = 20);\n",
    "\n",
    "# 154 principal components\n",
    "plt.subplot(1, 2, 2);\n",
    "plt.imshow(reconstruction[1].reshape(28, 28))\n",
    "plt.xlabel('332 components', fontsize = 14)\n",
    "plt.title('95% of Explained Variance', fontsize = 20);\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# code here \n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(feat[1].reshape(28, 28))\n",
    "plt.xlabel('784 components')\n",
    "plt.title('Original Image')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(reconstruction[1].reshape(28, 28))\n",
    "plt.xlabel('332 components')\n",
    "plt.title('95% of Explained Variance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above, we can see that even with such a huge reduction in the number of features, the the image is still maintaining most of its identifying characteristics. There is some noise apparent in the data as a result of this. However, we will shortly see that for classification purpose, it doesn't harm the analysis too much. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation for Explained Variance vs. Number of components\n",
    "\n",
    "In order to see how variance and numbers of components relate to each other, we can calculate variance explained with respect to number of components. Such analysis could be a useful way to get an objective indication on how much dimensionality reduction can we perform, and at what cost in terms of variance retention. \n",
    "\n",
    "Let's run another instance of PCA without specifying the dimensions or variance as shown below:\n",
    "\n",
    "```python\n",
    "# if n_components is not set all components are kept (784 in this case)\n",
    "pca = PCA()\n",
    "pca.fit(digits.data)\n",
    "pca.n_components_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here\n",
    "pca = PCA()\n",
    "pca.fit(digits.data)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the number of components here is exactly the same as number of features in the original dataset as expected. Let's calculate the total variance explained by these 784 components. \n",
    "\n",
    "```python\n",
    "# Summing explained variance\n",
    "tot = sum(pca.explained_variance_)\n",
    "tot\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "tot = sum(pca.explained_variance_)\n",
    "tot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a huge numbers here. That is because the variance is not normalized in this case. We can normalize each variance value explained by individual components and normalize it as below:\n",
    "```python\n",
    "# Normalized explained variance\n",
    "var_exp = [(i/tot)*100 for i in sorted(pca.explained_variance_, reverse=True)] \n",
    "print(var_exp[0:5])\n",
    "sum(var_exp)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "var_exp = [(i/tot) * 100 for i in sorted(pca.explained_variance_, reverse=True)]\n",
    "print(var_exp[0:5])\n",
    "sum(var_exp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks much better. Our values show a percentage of variance explained. Also `reverse=True` arranges these values in a descending order. Now we can calculate the cumulative variance as we add more dimensions , starting from 1 and going all the way to 784. We can use numpy's `cumsum()` to achieve this. \n",
    "\n",
    "```python\n",
    "# Cumulative explained variance\n",
    "cum_var_exp = np.cumsum(var_exp) \n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(cum_var_exp)\n",
    "plt.title('Cumulative Explained Variance as a Function of the Number of Components');\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.plot(cum_var_exp)\n",
    "plt.title('Cumulative Explained Variance as a Function of the Number of Components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we see a cumulative function for variance explained with respect to number of components. LEt's add a bit more information to this plot and make it more meaningful. \n",
    "\n",
    "```python\n",
    "# Cumulative Variance w.r.t. number of components\n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.step(range(1, 785), cum_var_exp, where='mid',label='Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance as a Function of the Number of Components')\n",
    "plt.ylabel('Cumulative Explained variance')\n",
    "plt.xlabel('Principal components')\n",
    "plt.axhline(y = 95, color='k', linestyle='--', label = '95% Explained Variance')\n",
    "plt.axhline(y = 90, color='c', linestyle='--', label = '90% Explained Variance')\n",
    "plt.axhline(y = 85, color='r', linestyle='--', label = '85% Explained Variance')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "plt.style.use('ggplot')\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.step(range(1, 785), cum_var_exp, where='mid', label='Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance as a Function of the Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.xlabel('Principal components')\n",
    "plt.axhline(y=95, color='k', linestyle='--', label='95% Explained Variance')\n",
    "plt.axhline(y=90, color='c', linestyle='--', label='90% Explained Variance')\n",
    "plt.axhline(y=85, color='r', linestyle='--', label='85% Explained Variance')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This explains a lot. We need around 238 components to explain 90% of varaince. Around 150 components for 80% variance , and so on. Let's get an idea about components required for a number of variance values, so we can visually inspect how components and variance relates to the appearance of images in the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check tour cumulative function for any particular variance value and see how many components do we need. Let's check this for 99%, 95%, 90%, and 85% of Explained Variance\n",
    "```python\n",
    "# check number of components for given explained variance\n",
    "componentsVariance = [784, np.argmax(cum_var_exp > 99) + 1, \n",
    "                      np.argmax(cum_var_exp > 95) + 1, \n",
    "                      np.argmax(cum_var_exp > 90) + 1, \n",
    "                      np.argmax(cum_var_exp >= 85) + 1] #Â Adding one as index starts from 0.\n",
    "componentsVariance\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "componentsVariance = [784, np.argmax(cum_var_exp > 99) + 1, np.argmax(cum_var_exp > 95) + 1,\n",
    "                     np.argmax(cum_var_exp > 90) + 1, np.argmax(cum_var_exp >= 85) +1]\n",
    "componentsVariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize PCA Images \n",
    "\n",
    "So how does all of above actually effect the visual aspect of the image. Let's write a simple function that accept percentage variance required with the image dataset to run PCA and return the images post-PCA. \n",
    "\n",
    "```python\n",
    "# Run PCA on a given dataset with explained variance\n",
    "n_comp = 0 # For storing current number of components\n",
    "\n",
    "def explainedVariance(percentage, images): \n",
    "    global n_comp #Â write global variable\n",
    "    \n",
    "    # percentage should be a decimal from 0 to 1 \n",
    "    pca = PCA(percentage)\n",
    "    pca.fit(images)\n",
    "    components = pca.transform(images)\n",
    "    #Â Apply inverse transform as seen above\n",
    "    approxOriginal = pca.inverse_transform(components)\n",
    "    n_comp = pca.n_components_\n",
    "    return approxOriginal\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "n_comp = 0\n",
    "\n",
    "def explainedVariance(percentage, images):\n",
    "    global n_comp\n",
    "    \n",
    "    pca = PCA(percentage)\n",
    "    pca.fit(images)\n",
    "    components = pca.transform(images)\n",
    "    approxOriginal = pca.inverse_transform(components)\n",
    "    n_comp = pca.n_components_\n",
    "    return approxOriginal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call this function repeatedly with defined explained variance values and select an image to inspect the impact of component count on how the images appears. \n",
    "\n",
    "```python\n",
    "#Â Show image quality loss with respect to reduction in principal components\n",
    "plt.style.use('seaborn-dark')\n",
    "plt.figure(figsize=(20,4));\n",
    "\n",
    "# Original Image (784 components)\n",
    "plt.subplot(1, 5, 1);\n",
    "plt.imshow(digits.data[-1].reshape(28,28));\n",
    "plt.xlabel('784 Components', fontsize = 12)\n",
    "plt.title('Original Image', fontsize = 14);\n",
    "\n",
    "plt.subplot(1, 5, 2);\n",
    "plt.imshow(explainedVariance(.99, digits.data)[-1].reshape(28, 28));\n",
    "plt.title('99% of Explained Variance', fontsize = 14);\n",
    "plt.xlabel(str(n_comp)+ ' Components')\n",
    "\n",
    "plt.subplot(1, 5, 3);\n",
    "plt.imshow(explainedVariance(.95, digits.data)[-1].reshape(28, 28));\n",
    "plt.title('95% of Explained Variance', fontsize = 14);\n",
    "plt.xlabel(str(n_comp)+ ' Components')\n",
    "\n",
    "plt.subplot(1, 5, 4);\n",
    "plt.imshow(explainedVariance(.90, digits.data)[-1].reshape(28, 28));\n",
    "plt.title('90% of Explained Variance', fontsize = 14);\n",
    "plt.xlabel(str(n_comp)+ ' Components')\n",
    "\n",
    "plt.subplot(1, 5, 5);\n",
    "plt.imshow(explainedVariance(.85, digits.data)[-1].reshape(28, 28));\n",
    "plt.title('85% of Explained Variance', fontsize = 14);\n",
    "plt.xlabel(str(n_comp)+ ' Components')\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "plt.style.use('seaborn-dark')\n",
    "plt.figure(figsize=(20, 4))\n",
    "plt.subplot(1, 5, 1)\n",
    "plt.imshow(digits.data[-1].reshape(28, 28))\n",
    "plt.xlabel('784 Components')\n",
    "plt.title('Original Image')\n",
    "\n",
    "plt.subplot(1, 5, 2);\n",
    "plt.imshow(explainedVariance(.99, digits.data)[-1].reshape(28, 28));\n",
    "plt.title('99% of Explained Variance', fontsize = 14);\n",
    "plt.xlabel(str(n_comp)+ ' Components')\n",
    "\n",
    "plt.subplot(1, 5, 3);\n",
    "plt.imshow(explainedVariance(.95, digits.data)[-1].reshape(28, 28));\n",
    "plt.title('95% of Explained Variance', fontsize = 14);\n",
    "plt.xlabel(str(n_comp)+ ' Components')\n",
    "\n",
    "plt.subplot(1, 5, 4);\n",
    "plt.imshow(explainedVariance(.90, digits.data)[-1].reshape(28, 28));\n",
    "plt.title('90% of Explained Variance', fontsize = 14);\n",
    "plt.xlabel(str(n_comp)+ ' Components')\n",
    "\n",
    "plt.subplot(1, 5, 5);\n",
    "plt.imshow(explainedVariance(.85, digits.data)[-1].reshape(28, 28));\n",
    "plt.title('85% of Explained Variance', fontsize = 14);\n",
    "plt.xlabel(str(n_comp)+ ' Components')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see what \"visually\" happenes to the image as we reduce the number of components. Try running above routine again and check for lower values of explained variance. Also, check for different digits randomly from the dataset. This helps you make an informed decision about the quality-speed trade off. \n",
    "\n",
    "Visually, we may still be able to identify a 9 or any other digit. The real test here would be to pass this image data to a classifier and see how it performs. Let's try this with a simple multinomial logistic regression classifier next. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifying Images using Learned Components \n",
    "\n",
    "Following the standard supervised learning practice, we shall split our data into train and test sets using a 75/25 split. You can try different split levels and see how it impacts the performance. \n",
    "\n",
    "```python\n",
    "#Â Create training and test datasets from standardized data \n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=0.25, random_state=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "X_train, X_test, y_train, y_test = train_test_split(digits.data, digits.target, test_size=.25, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply PCA as a preprocessing technique\n",
    "\n",
    "We can now apply PCA on the training dataset while keeping 90% of explained variance. Again, you should try different values and study the impact on the outcome.\n",
    "\n",
    "```python\n",
    "#Â Run PCA with 90% explained variance\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.90) #Â Retain 95% of the variance\n",
    "pca.fit(X_train)from \n",
    "pca.n_components_\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # code here \n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(.90)\n",
    "pca.fit(X_train)\n",
    "pca.n_components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create our transformed training and test sets for logistic regression classifier as shown below:\n",
    "\n",
    "```python\n",
    "#Â Run a logistic regression classifier on transformed datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create transformed test and train sets \n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "# default solver is incredibly slow thats why we change it to solver = 'lbfgs' (BroydenâFletcherâGoldfarbâShanno algorithm)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver = 'lbfgs')\n",
    "logisticRegr.fit(X_train, y_train)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "X_train = pca.transform(X_train)\n",
    "X_test = pca.transform(X_test)\n",
    "\n",
    "logisticRegr = LogisticRegression(solver='lbfgs')\n",
    "logisticRegr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions and Check Performance\n",
    "\n",
    "Great, we can now try to predict the label for a given example in the test set as shown below:\n",
    "```python\n",
    "# Predict for a random Observation (image)\n",
    "logisticRegr.predict(X_test[0].reshape(1,-1)) #Â predict the label of first image in transformed test set\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "logisticRegr.predict(X_test[0].reshape(1, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can check for the actual label in our target test set. \n",
    "```python\n",
    "# View label from target \n",
    "y_test[0]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "y_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly we can try a sequence of images and get the labels as shown below  \n",
    "```python\n",
    "#Â Get labels for a random sequence of images\n",
    "list(zip(logisticRegr.predict(X_test[0:10]), y_test)) \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here \n",
    "list(zip(logisticRegr.predict(X_test[0:10]), y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. All predicted labels are exactly same as the ground truth. To get an over all objective assessment of this classification, we can calculate the classification score using the built in method as below:\n",
    "```python\n",
    "# Calculate the classification score \n",
    "score = logisticRegr.score(X_test, y_test)\n",
    "print(score)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9171428571428571\n"
     ]
    }
   ],
   "source": [
    "# code here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have 91% accuracy, with 229 components. This sounds great. We have managed to compress our data from 700+ features to just 229 components (1/3 of original data and can still achieve a high level of classification accuracy. We have run above experiments with classifiers mostly in their vanilla settings. Fine tuning and optimization techniques may help us increase this score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level up - Optional \n",
    "\n",
    "- Change the code above and calculate components, time taken and classification score for explained variance as shown in the table below. Fill the outcomes in the given table. \n",
    "\n",
    "```\n",
    "\n",
    "Variance \tNumber of       Time (seconds)      Score\n",
    "Retained    Components\n",
    "\n",
    "1.00\t\n",
    "0.95\t\n",
    "0.90\t\n",
    "0.85\t\n",
    "0.80\n",
    "0.70\n",
    "```\n",
    "- Run the experiment without standardization and record your observations.\n",
    "- Try other classifiers that you are familiar with to study the impact on PCA on each. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary \n",
    "\n",
    "In this code along, we looked at the role of PCA in basic image processing with MNIST dataset. Image datasets tend to be very large in size and PCA allows us to use a compressed (or reduced) representation of image data to fulfil the analyses needs. Next, we shall see how these techniques may be applied to slightly more complex image data i.e. human faces with Eigenfaces. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
